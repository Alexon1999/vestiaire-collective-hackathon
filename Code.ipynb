{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon Vestiaire Collective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Project summary\n",
    "- Import libraries\n",
    "- 1: EDA & CORR\n",
    "- 2: PREPROCESSING\n",
    "- 3: BUILD BASELINE\n",
    "- 4: XGBOOST\n",
    "- 5: LGBM\n",
    "- 6: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables description\n",
    "\n",
    "- TIME_ONLINE : How long the products stayed online. In days.\n",
    "- DEPOSIT_PRICE : The price at which the product was deposited on the platform (euros).\n",
    "- PRICE : The online price (euros).\n",
    "- NON_RECEIVED_PCT : The percentage of products of the given seller that ended up generating a Reimbursement action.\n",
    "- TOTAL_SELLER_CANCELLED : The total number of seller cancellations.\n",
    "- RANK_SOLD : The rank of the seller.\n",
    "- NB_WIDTHDRAW_SELLER_7D : The number of product withdrawals made by the seller within 7 days.\n",
    "---\n",
    "- Label : Whether the sale was canceled or not. 1 means \"canceled\". 0 means \"not canceled\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stats\n",
    "print(\"Number of rows : {}\".format(data.shape[0]))\n",
    "print(\"Number of columns : {}\".format(data.shape[1]))\n",
    "print()\n",
    "\n",
    "print(\"Display of dataset: \")\n",
    "display(data.head())\n",
    "print()\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc = data.describe(include='all')\n",
    "display(data_desc)\n",
    "print()\n",
    "\n",
    "print(\"Missing values per column: \")\n",
    "display((data.isnull().sum()).sort_values(ascending=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of LABEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>0 : Sale succeeded</font>\n",
    "\n",
    "<font color='red'>1 : Sale canceled</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"LABEL\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LABEL'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(corr, annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis\n",
    "##### Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['PRICE', 'INSERTION_PRICE', 'DEPOSIT_PRICE', 'TIME_ONLINE' , 'NB_DAYS_SINCE_LAST_SOLD', 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 20))\n",
    "for i in range(0, len(numeric_features)):\n",
    "    plt.subplot(4, int(len(numeric_features)/3), i+1)\n",
    "    sns.boxplot(y=data[numeric_features[i]], color='gray', orient='v')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numeric_features:\n",
    "    viz = px.scatter(data, x = i,color='LABEL')\n",
    "    display(viz)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assumptions from Relationships\n",
    "- When the time online increase, thr price decrease ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x = 'TIME_ONLINE' , y = 'DEPOSIT_PRICE' , data = dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When there are more withdrawals, le vendeur a plus tendance Ã  annuler sa vente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"NB_WIDTHDRAW_SELLER_7D\", y=\"LABEL\", data= dataset, logistic = True, scatter_kws={\"alpha\":.05})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.TIME_ONLINE < 1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "features = data.columns.values[:-1]\n",
    "target = data.columns.values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label list\n",
    "features_label = data.columns.to_list()\n",
    "target_label = features_label.pop(features_label.index('LABEL'))\n",
    "target_label = [target_label]\n",
    "\n",
    "numerical_label = features_label.copy()\n",
    "\n",
    "categorical_label = numerical_label.pop(numerical_label.index('ID_PRODUCT'))\n",
    "categorical_label = [categorical_label]\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_SELLER')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_SELLER_COUNTRY')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('SELLER_GEO_1')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('SELLER_GEO_2')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('SELLER_GEO_3')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('SEGMENT')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('BRAND_GROUP')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_BRAND')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_PAGE')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_SITE')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('LANGUAGE')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_UNIVERSE')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_CATEGORY')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_SUB_SUBCATEGORY')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_MODEL')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_MATERIAL')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_COLOUR')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_PATTERN')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('CURRENCY')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('ID_CONDITION')))\n",
    "categorical_label.append(numerical_label.pop(numerical_label.index('DEPOSIT_DEVICE')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_label),\n",
    "        ('cat', cat_transformer, categorical_label)\n",
    "    ])\n",
    "X_train = preprocess.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter=100000) \n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = classifier.predict_proba(X_train)\n",
    "Y_test_pred = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average-precision-score on train set : \", average_precision_score(Y_train, Y_train_pred[:,1]))\n",
    "print(\"average-precision-score on test set : \", average_precision_score(Y_test, Y_test_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_train_pred = model.predict_proba(X_train)\n",
    "Y_test_pred = model.predict_proba(X_test)\n",
    "print(\"average-precision-score on train set : \", average_precision_score(Y_train, Y_train_pred[:,1]))\n",
    "print(\"average-precision-score on test set : \", average_precision_score(Y_test, Y_test_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = {\"subsample\":[0.5, 0.75, 1],\n",
    "              \"colsample_bytree\":[0.5, 0.75, 1],\n",
    "              \"max_depth\":[2, 6, 12],\n",
    "              \"min_child_weight\":[1,5,15],\n",
    "              \"learning_rate\":[0.3, 0.1, 0.03],\n",
    "              \"n_estimators\":[100]}\n",
    "\n",
    "\n",
    "model = LGBMClassifier()\n",
    "model_gs = GridSearchCV(model,param_grid=PARAMETERS,cv=3,scoring=\"accuracy\",verbose=3, n_jobs=-1)\n",
    "model_gs.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lgb_train_pred = model_gs.predict_proba(X_train)\n",
    "grid_lgb_test_pred = model_gs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average-precision-score on train set : \", average_precision_score(Y_train, grid_lgb_train_pred[:,1]))\n",
    "print(\"average-precision-score on test set : \", average_precision_score(Y_test, grid_lgb_test_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model : LGBM, fit on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data[numerical_label]\n",
    "#Y =  data['LABEL']\n",
    "X = data.loc[:, features]\n",
    "Y = data.loc[:, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_label),\n",
    "        ('cat', cat_transformer, categorical_label)\n",
    "    ])\n",
    "X = preprocess.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCLF = LGBMClassifier()\n",
    "LCLF.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv('test.csv',index_col=0)\n",
    "test_sub = preprocess.transform(test_sub)\n",
    "test_sub_pred = LCLF.predict_proba(test_sub)[:,1]\n",
    "# Save prediction\n",
    "submission = pd.DataFrame({'LABEL': test_sub_pred})\n",
    "submission.reset_index(inplace=True)\n",
    "submission.to_csv('sub/submission3.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66168a667a11ac16aca0d0d9742c8419f93457ff66115bf85239ea370d417636"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
